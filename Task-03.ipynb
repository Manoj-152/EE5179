{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 03:\n",
    "\n",
    "In this task, you have to implement the Backpropagation method using Pytorch. This is particularly useful when the hypothesis function contains several weights.\n",
    "\n",
    "**Backpropagation**: Algorithm to caculate gradient for all the weights in the network with several weights. \n",
    "\n",
    "* It uses the `Chain Rule` to calcuate the gradient for multiple nodes at the same time. \n",
    "* In pytorch this is implemented using a `variable` data type and `loss.backward()` method to get the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import the necessary libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries - Pytorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# creating a tensor\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# zero tensor\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m zeros \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(zeros)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# ones\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# creating a tensor\n",
    "\n",
    "# zero tensor\n",
    "zeros = torch.zeros(5)\n",
    "print(zeros)\n",
    "# ones\n",
    "ones = torch.ones(5)\n",
    "print(ones)\n",
    "# random normal\n",
    "random = torch.randn(5)\n",
    "print(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_list = [0.0, 1.0, 2.0, 3.0, 4.0]\n",
    "# YOUR CODE STARTS HERE\n",
    "floats_to_tensor = \n",
    "#YOUR CODE ENDS HERE\n",
    "print(\"The dtype of tensor object after converting it to tensor: \", floats_to_tensor.dtype)\n",
    "print(\"The type of tensor object after converting it to tensor: \", floats_to_tensor.type())\n",
    "print(\"The size of the floats_to_tensor: \", floats_to_tensor.size())\n",
    "print(\"The dimension of the floats_to_tensor: \",floats_to_tensor.ndimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 2 :\n",
    "Convert the given numpy array to a torch tensor and again back to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [[11, 12, 13], [21, 22, 23], [31, 32, 33]]\n",
    "\n",
    "numpy_array = np.asarray(my_list)\n",
    "print(\"The numpy array: \", numpy_array)\n",
    "print(\"Type : \", numpy_array.dtype)\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "tensor_array = \n",
    "#YOUR CODE ENDS HERE\n",
    "print(\"\\nNumpy Array -> Tensor:\")\n",
    "print(\"The tensor after converting:\", tensor_array)\n",
    "print(\"Type after converting: \", tensor_array.dtype)\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "new_numpy_array = \n",
    "#YOUR CODE ENDS HERE\n",
    "print(\"\\nTensor -> Numpy Array:\")\n",
    "print(\"The numpy array after converting: \", new_numpy_array)\n",
    "print(\"Type after converting: \", new_numpy_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise 3 :\n",
    "Determine the derivative of $y = 2x^{3} + x$ at $x = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "x = \n",
    "y = \n",
    "\n",
    "# YOUR CODE ends HERE\n",
    "print(\"Value of Y at x=1 : \" , y)\n",
    "print(\"Derivative of Y wrt x at x=1 : \" , x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excersie 4 :\n",
    "Determine the partial derivative of $y = uv + u^{2}$ at $u=1$ and $v=2$ with respect to $u$ and $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "u = \n",
    "v = \n",
    "y =\n",
    "\n",
    "# YOUR CODE ends HERE\n",
    "print(\"Value of y at u=1, v=2 : \" , y)\n",
    "print(\"Partial Derivative of y wrt u : \" , u.grad)\n",
    "print(\"Partial Derivative of y wrt v : \" , v.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Function and Loss Function\n",
    "\n",
    "$y = x * w + b$\n",
    "\n",
    "$loss =(\\hat{y}-y)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make use of a randomly-created sample dataset as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample-dataset\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: 03 - a\n",
    "Declare pytorch tensors for weight and bias and implement the forward and loss function of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define w = 1 and b = -1 for y = wx + b\n",
    "# Note that w,b are learnable paramteter \n",
    "# i.e., you are going to take the derivative of the tensor(s).\n",
    "# YOUR CODE STARTS HERE\n",
    "w = \n",
    "b = \n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "assert w.item() == 1\n",
    "assert b.item() == -1\n",
    "assert w.requires_grad == True\n",
    "assert b.requires_grad == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward function to calculate y_pred for a given x according to the linear model defined above\n",
    "def forward(x):\n",
    "    #implement the forward model to compute y_pred as w*x + b\n",
    "    ## YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "    ## YOUR CODE ENDS HERE\n",
    "\n",
    "#loss-function to compute the mean-squared error between y_pred and y_actual\n",
    "def loss(y_pred, y_actual):\n",
    "    #calculate the mean-squared-error between y_pred and y_actual\n",
    "    ## YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "    ## YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $y_{pred}$ for $x=4$ without training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_without_train = forward(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this method, we learn the dataset multiple times (called epochs)\n",
    "# Each time, the weight (w) gets updates using the graident decent algorithm based on weights of the previous epoch\n",
    "\n",
    "alpha = 0.01 # Let us set learning rate as 0.01\n",
    "weight_list = []\n",
    "loss_list=[]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for x, y in zip(x_data, y_data):\n",
    "        \n",
    "        #implement forward pass, compute loss and gradients for the weights and update weights\n",
    "        ## YOUR CODE STARTS HERE\n",
    "        \n",
    "        ## YOUR CODE ENDS HERE\n",
    "\n",
    "        # Manually zero the gradients after updating weights\n",
    "        w.grad.data.zero_()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    avg_mse = total_loss / count        \n",
    "    print(f\"Epoch: {epoch+1} | Loss: {avg_mse.item()} | w: {w.item()}\")\n",
    "    weight_list.append(w)\n",
    "    loss_list.append(avg_mse)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $y_{pred}$ for $x=4$ after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_train = forward(4)\n",
    "\n",
    "print(\"Actual Y Value for x=4 : 8\")\n",
    "print(\"Predicted Y Value before training : \" , y_pred_without_train.item())\n",
    "print(\"Predicted Y Value after training : \" , y_pred_with_train.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: 03 - b\n",
    "Repeat **Task:03 - a** for the quadratic model defined below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using backward propagation for quadratic model\n",
    "\n",
    "$\\hat{y} = x^2*w_{2} + x*w_{1}$\n",
    "\n",
    "$loss = (\\hat{y}-y)^2$\n",
    "\n",
    "* Using Dummy values of x and y\n",
    "\n",
    "`x = 1,2,3,4,5`\n",
    "`y = 1,6,15,28,45`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "y_data = [1.0, 6.0, 15.0, 28, 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the given dataset\n",
    "plt.plot(x_data,y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize w2 and w1 with randon values\n",
    "w_1 = torch.tensor([1.0], requires_grad=True)\n",
    "w_2 = torch.tensor([1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wuadratic-forward function to calculate y_pred for a given x according to the quadratic model defined above\n",
    "def quad_forward(x):\n",
    "    #implement the forward model to compute y_pred as w1*x + w2*(x^2)\n",
    "    ## YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "    ## YOUR CODE ENDS HERE\n",
    "\n",
    "#loss-function to compute the mean-squared error between y_pred and y_actual\n",
    "def loss(y_pred, y_actual):\n",
    "    #calculate the mean-squared-error between y_pred and y_actual\n",
    "    ## YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "    ## YOUR CODE ENDS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $y_{pred}$ for $x=6$ without training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_without_train = quad_forward(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this method, we learn the dataset multiple times (called epochs)\n",
    "# Each time, the weight (w) gets updates using the graident decent algorithm based on weights of the previous epoch\n",
    "\n",
    "alpha = 0.0012 # Let us set learning rate as 0.01\n",
    "weight_list = []\n",
    "loss_list=[]\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for x, y in zip(x_data, y_data):\n",
    "        \n",
    "        #implement forward pass, compute loss and gradients for the weights and update weights\n",
    "        ## YOUR CODE STARTS HERE\n",
    "        \n",
    "        ## YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Manually zero the gradients after updating weights\n",
    "        w_1.grad.data.zero_()\n",
    "        w_2.grad.data.zero_()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "    avg_mse = total_loss / count        \n",
    "    print(f\"Epoch: {epoch+1} | Loss: {avg_mse.item()} | w: {w.item()}\")\n",
    "    weight_list.append(w)\n",
    "    loss_list.append(avg_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $y_{pred}$ for $x=6$ after training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_with_train = forward(6)\n",
    "\n",
    "print(\"Actual Y Value for x=4 : 66\")\n",
    "print(\"Predicted Y Value before training : \" , y_pred_without_train.item())\n",
    "print(\"Predicted Y Value after training : \" , y_pred_with_train.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
